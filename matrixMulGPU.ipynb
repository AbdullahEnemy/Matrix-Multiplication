{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1tvnUkBT_M70",
        "outputId": "59ceabcf-53b0-4b66-b495-7a70d94a927c"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting nvcc4jupyter\n",
            "  Downloading nvcc4jupyter-1.2.1-py3-none-any.whl (10 kB)\n",
            "Installing collected packages: nvcc4jupyter\n",
            "Successfully installed nvcc4jupyter-1.2.1\n",
            "Detected platform \"Colab\". Running its setup...\n",
            "Source files will be saved in \"/tmp/tmpfyc1k3zk\".\n"
          ]
        }
      ],
      "source": [
        "!pip install nvcc4jupyter\n",
        "%load_ext nvcc4jupyter"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%%cuda\n",
        "#include <iostream>\n",
        "#include <sys/time.h>\n",
        "#include <cstdlib>\n",
        "\n",
        "// measuring execution time\n",
        "struct timeval start, end;\n",
        "double cpu_time_used;\n",
        "\n",
        "__global__ void matrixMulKernel(float* A, float* B, float* C, int width) {\n",
        "    int row = blockIdx.y * blockDim.y + threadIdx.y;\n",
        "    int col = blockIdx.x * blockDim.x + threadIdx.x;\n",
        "\n",
        "    if (row < width && col < width) {\n",
        "        float sum = 0.0f;\n",
        "        for (int i = 0; i < width; ++i) {\n",
        "            sum += A[row * width + i] * B[i * width + col];\n",
        "        }\n",
        "        C[row * width + col] = sum;\n",
        "    }\n",
        "}\n",
        "\n",
        "void printMatrix(const float* matrix, int m, int n)\n",
        "{\n",
        "    for (int i = 0; i < m; i++)\n",
        "    {\n",
        "        for (int j = 0; j < n; j++)\n",
        "            printf(\"%f \", matrix[(i * 4096 + j)]);\n",
        "        printf(\"...\\n\");\n",
        "    }\n",
        "    printf(\".\\n.\\n.\\n\\n\");\n",
        "}\n",
        "\n",
        "\n",
        "int main()\n",
        "{\n",
        "    srand(time(NULL));\n",
        "\n",
        "    const float width = 4096;\n",
        "    const size_t size = width * width * sizeof(float);\n",
        "\n",
        "    float* h_A = (float*)malloc(size);\n",
        "    float* h_B = (float*)malloc(size);\n",
        "    float* h_C = (float*)malloc(size);\n",
        "\n",
        "    for (int i = 0; i < width * width; ++i) {\n",
        "        h_A[i] = static_cast<float>(rand()) / RAND_MAX;\n",
        "        h_B[i] = static_cast<float>(rand()) / RAND_MAX;\n",
        "    }\n",
        "\n",
        "    float* d_A, *d_B, *d_C;\n",
        "    cudaMalloc((void**)&d_A, size);\n",
        "    cudaMalloc((void**)&d_B, size);\n",
        "    cudaMalloc((void**)&d_C, size);\n",
        "\n",
        "    // Copy matrices from host to device\n",
        "    cudaMemcpy(d_A, h_A, size, cudaMemcpyHostToDevice);\n",
        "    cudaMemcpy(d_B, h_B, size, cudaMemcpyHostToDevice);\n",
        "\n",
        "    // Define grid and block dimensions\n",
        "    dim3 blockDim(32, 32);\n",
        "    dim3 gridDim((width + blockDim.x - 1) / blockDim.x, (width + blockDim.y - 1) / blockDim.y);\n",
        "\n",
        "    // Launch kernel\n",
        "    gettimeofday(&start, NULL);\n",
        "    matrixMulKernel<<<gridDim, blockDim>>>(d_A, d_B, d_C, width);\n",
        "    gettimeofday(&end, NULL);\n",
        "    cpu_time_used = (double)(end.tv_sec - start.tv_sec) + (double)(end.tv_usec - start.tv_usec) / 1000000.0;\n",
        "\n",
        "    // Copy result matrix from device to host\n",
        "    cudaMemcpy(h_C, d_C, size, cudaMemcpyDeviceToHost);\n",
        "\n",
        "    // printMatrix(h_A, 10, 10);\n",
        "    // printMatrix(h_B, 10, 10);\n",
        "    // printMatrix(h_C, 10, 10);\n",
        "    printf(\"Finished in %lf seconds...\\n\", cpu_time_used);\n",
        "\n",
        "    // Free device memory\n",
        "    cudaFree(d_A);\n",
        "    cudaFree(d_B);\n",
        "    cudaFree(d_C);\n",
        "\n",
        "    // Free host memory\n",
        "    free(h_A);\n",
        "    free(h_B);\n",
        "    free(h_C);\n",
        "\n",
        "    return 0;\n",
        "}"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BQaFt4oR_t1O",
        "outputId": "d1c70ca0-c998-4ca8-afb0-d804b2cf00b6"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Finished in 0.000192 seconds...\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "yyZ8LREI_9J8"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}